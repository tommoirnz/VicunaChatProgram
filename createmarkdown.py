# Define your summary text (copy the text from the previous response)
summary_text = """
# Program Summary

## Main Components

### Imports and Libraries  
The code uses a wide range of libraries:
- **System and Threading:** Modules like `os`, `sys`, and `threading` handle system operations and concurrent tasks.
- **GUI:** Tkinter (with themed widgets via `ttk`) is used to create multiple windows (main app, transcript window, chat window).
- **Audio & Speech Processing:**  
  - `sounddevice` and `numpy` manage real-time audio input and processing.
  - `speech_recognition` (with Google's API) converts spoken audio to text.
- **Text-to-Speech (TTS):**  
  - `edge_tts` for Microsoft Edge TTS functionality, with a fallback using `pyttsx3` (SAPI5 on Windows).
  - Audio playback is managed via `simpleaudio` and `sounddevice`.
- **Deep Learning and Language Model:**  
  - PyTorch (`torch`) and Hugging Face’s `transformers` are used to load and interact with the Vicuna language model.
- **Other Utilities:**  
  - `asyncio` for asynchronous TTS calls, `tempfile` for temporary file management, and `matplotlib` with `PIL` for rendering chat content as a LaTeX-like image.

### Global Queues and Variables  
The program maintains several queues to handle asynchronous tasks:
- A transcription queue for audio-to-text outputs.
- A Vicuna response queue for managing chat responses.
- A volume queue to update a live volume meter.

Global variables are also used to manage TTS playback states and voice settings for both Edge TTS and SAPI TTS.

### TTS Functionality  
- **Edge TTS:**  
  The `speak_text_global` function asynchronously generates speech from text using the Edge TTS service. It saves the output as an MP3 file, loads it into an audio segment (via `pydub`), and plays it either through `sounddevice` (if an output device is specified) or `simpleaudio`.
- **SAPI TTS:**  
  When selected, the program uses `pyttsx3` to generate speech via SAPI (Windows), running this in a separate thread to avoid blocking the GUI.

### GUI Design  
The application uses multiple Tkinter windows:
- **CombinedASRApp:**  
  The main window handles audio input, displays a live volume meter, and provides controls (like microphone selection, gain adjustment, buffer settings, and recording toggle).
- **TranscriptWindow:**  
  A dedicated window that continuously updates with transcribed text from the audio input, with options to adjust font size and save the transcript.
- **VicunaChatWindow:**  
  This window provides a chat interface where users can submit text (or transcriptions), view conversation history, and see responses generated by the Vicuna language model. It also integrates TTS options, allowing automatic playback of AI responses.

### Audio Processing and ASR  
- The audio callback in `CombinedASRApp` applies gain to incoming audio, updates a volume meter, and buffers audio chunks.
- Once the buffer reaches a set size (with an overlap for continuity), the audio is processed in a background thread to perform speech recognition via Google’s API.
- The recognized text is then sent to both the transcript display and the Vicuna chat window as user input.

### Vicuna Language Model Integration  
- The program sets up the Vicuna model using Hugging Face’s `transformers` library. It uses a 4-bit quantized model for efficiency.
- Conversation history is maintained, and user inputs are appended to a conversation log before generating a response with beam search (configurable via a spinbox in the GUI).
- Generated AI responses are queued for display and TTS playback.

### Additional Features  
- **Rendering Chat as LaTeX:**  
  The chat text can be rendered as an image using matplotlib, which can be useful for sharing or archiving the conversation in a stylized format.
- **Voice Auto-Detection:**  
  When an AI response is received, the program attempts to detect its language (using `langdetect`) and then automatically selects a default voice that matches the detected language.
- **Controls and User Interaction:**  
  There are buttons to clear chat, clear history, stop or replay TTS, and save transcripts—all of which improve the usability of the application.

## Summary

Overall, the program integrates real-time audio capture, speech-to-text, deep learning-based conversation (via Vicuna), and two forms of TTS into a cohesive GUI application. It’s designed for robust performance with features like multithreading (to handle asynchronous audio processing and TTS) and a user-friendly interface that gives control over audio devices, language selection, and TTS options.
"""

# Write the summary to a Markdown file
with open("program_summary.md", "w", encoding="utf-8") as md_file:
    md_file.write(summary_text)

print("Markdown file 'program_summary.md' created successfully!")
